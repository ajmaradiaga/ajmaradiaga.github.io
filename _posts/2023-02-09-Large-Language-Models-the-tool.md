---
layout: post
title: Large Language Models - the tool
---


Lately, it's been impossible to ignore all the news revolving around AI [Large Language Models](https://en.wikipedia.org/wiki/Wikipedia:Large_language_models) (LLMs). We are getting familiar with them and start to have an idea of what's possible. There's excitement and even fear around how it might impact our life's. In this blog post, I will share some of the benefits, problems, consequences, and even potential ways of how we can probably communicate that a piece of content is not entirely our creation.

![Red Led Light With Silhouette Of A Man by Akwice](https://images.pexels.com/photos/3094799/pexels-photo-3094799.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=1)

Source: Pexels.com - [Red Led Light With Silhouette Of A Man by Akwice](https://www.pexels.com/photo/red-led-light-with-silhouette-of-a-man-3094799/)  

----
> **TLDR; LLMs can be leveraged as another tool in your toolbox. It is not meant to substitute you.** 
----

I find very interesting that chatbots have been around for a while but they didn‚Äôt truly take off because of their limited functionality and now the future of search will be a chat-style conversation. [Microsoft is reinventing search](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/) by incorporating OpenAI's ChatGPT in Bing. [Google is talking about Bard](https://blog.google/technology/ai/bard-google-ai-search-updates/) and how it will be included within their search. Something that we can see is that the way we interact with search will definitely change and it will be more of a conversational-style. Which comes in quite handy as these application seem to maintain the context of previous searches to provide new answers and this way you can dive deeper on your search. Compare to how we do it now, that we need to craft good search queries to find more information. Now, there is a big problem here.... you will be able to understand concepts faster, maybe even better, but you will not have content to reference to as these models don't share the sources where you can find the original ideas that have been used to synthesise/summarise the text that's been generated.

These obviously have large implications on how we interact with services, how we create, how we consume information, even how we can interact with others. That said, I will like to share how I see these LLMs being used in positive and negative ways.  

### Using LLMs negatively....

- _Substitute your creative process_: It is true that in order for an AI model to generate text/image, it will require an input, which will be provided by the user but just providing that input, in my opinion, doesn't make you the creator of the content. The way I see it, just copying the content output by the AI model and attributing it to yourself as original is along the lines of plagiarism. Also, remember that the output of these models use very generic words and it might end up sounding very bland. The LLM doesn't generate text as you will write, it's not "your voice'". I would say that an audience will not be able to connect with you as an author if it doesn't sound like you. Also, will you memorise the text before publishing? What if someone asks you a question about the text and you have no idea about it. You might not have a reason why a particular sentence made it to the published text. I personally enjoy the creative/research process I go through when writing a blog post, preparing a speech/presentation‚Ä¶. I don‚Äôt want an AI to take that joy away from me.  
- _Generating content that others need to trust_: Remember that the data used to train these models comes from crawling the web, and there is a lot of information out there that is not true. Meaning, it is possible that the LLM outputs something that can misinform. These can also be applied to generated content that others might use as reference, advice, to learn. I hope our politicians don't start using LLMs to draft our future laws, e.g. generate massive amounts of text that will make them unreadable and no one will have the time/patience to properly read what's there before it goes to vote, or that someone starts generating medical-related articles using an LLM and starts publishing them on the web. Using/publishing generated content can erode the trust that the reader/viewer might have on you. Personally, I have limited time to reading and I prefer to dedicate that time reading someone I can trust.
- _Creating the report/essay/thesis that you are being evaluated on_: Yeah, education. We've seen the news of [ChatGTP passing an MBA exam](https://interestingengineering.com/innovation/chatgpt-passes-wharton-business-schools-mba-exam-gets-a-b). You might think that you are fooling the evaluator but the reality is that you are just fooling yourself if you are presenting something as your own when you need to demonstrate/express your learning/understanding and this has been generated by an LLM. Also, you are not able to verify the sources used to train an LLM. It is not a reliable source of information.

### Using LLMs positively....

- *Input for ideas*: Similar to how we can grab a book/website on a subject and use it as an inspiration/input for our ideas. Not that long ago, a colleague of mine used an AI service to generate images based on an idea. He used this as inspiration to create a template/logo. This is a process similar to using a search engine, do a quick search based on keywords, move to the Images tab, see images that fit your idea and use them as input to create something.  
- *Get an overview or quick summary of a complex subject:* This is one of the most exciting uses that I see. As mentioned in [Sundar Pichai's blog post](https://blog.google/technology/ai/bard-google-ai-search-updates/), *how AI can deepen our understanding of information and turn it into useful knowledge more efficiently.* Here we are using AI as a tool that can help us understand/interpret something faster. I personally see myself using it this way to try to have a grasp on a complex subject and use it as a starting point before diving deeper on a subject.  
- *Automating boring stuff:* Not all text generation is bad, e.g. draft an out of office email reply, formulate a quick reply - thank you, no problem. It doesn't necessarily need to be boring.... it can be a short fiction story.  

In essence, leveraging an LLM as a tool üëá.

<blockquote
 class="twitter-tweet"><p lang="en" dir="ltr">AI will not 
replace you. A person using AI will.</p>&mdash; Santiago 
(@svpino) <a 
href="https://twitter.com/svpino/status/1610984481342771200?ref_src=twsrc%5Etfw">January
 5, 2023</a></blockquote>
 

We've seen what these LLMs are capable of... drafting comprehensive text that can be used as answers, as [articles](https://gizmodo.com/cnet-chatgpt-ai-articles-publish-for-months-1849976921), and even generating code. This last point raises the question.... which job will become obsolete if we start using this LLMs? For example, will it replace software developers? Let's dive a bit on this question...
- First of all, not all code generated by an LLM is perfect. It might not compile/run and it might require some tweaking. If so, someone needs to understand the programming language. Guess who understands programming languages? üßë‚Äçüíª  
- In my view, no. A software developer nowadays does a lot more than just writing code. A software developer is also responsible of architecting, testing, deploying, maintaining, monitoring, documenting (hopefully), and updating the services they create. That apart from listening to their customer/business needs/requirements, figuring out what is it that they really need and then producing a solution(s) that meets these needs/requirements. Writing code is one thing, having a proper solution built and maintained is way different.  
- Now, if all the code that you write is in an Excel spreadsheet then yeah.... maybe the LLM has included in its training [Visual Basic for Applications](https://learn.microsoft.com/en-us/office/vba/api/overview/excel/graph-visual-basic-reference) and it might be able to generate the code that you need. Programming in an environment, like an Excel spreadsheet, doesn't have the complexity that normal software development life cycles have. Another example will be generating a simple script, e.g. validate some type of data, that can be incorporated within a low-code/no-code tool.  
- What about something like GitHub Copilot? Yep, it is mind-blowing that you can write a comment and it then suggests you the code. This is a very interesting proposition and something that when leveraged as a tool can help you deliver products faster. That said, you still need to know exactly what you are adopting there. In the end, this is similar to finding a solution in [StackOverflow](https://stackoverflow.com/) and copying and pasting the code you find there :-). Use at your own risk. Also, that's only code... you still need to deploy it, maintain it, etc.

Now that these LLMs are going mainstream, as they are starting to be included within services/applications, we will start seeing more of it out there.... in the form of blog posts, articles, tweets, posts, etc. What can we do about it? In my opinion, we should inform the reader/viewer about it. How?  
- _Tag AI-generated text_: This is simple, if a published text includes AI-generated text, the text should be properly tagged and mention that that piece of text is AI-generated. Similar to how you quote others now.  
- _AI-generated banner on the website_: In the case that an article/content contains large amounts (if not all) AI-generated text, we should let the visitor know about it. Similar to how we now have [cookie consent banners](https://gdpr.eu/cookies/) on websites. These banners can be annoying but the goal is to inform the visitor of the source/trustiness of the content. As mentioned before, generated text might not be a reliable source of information.  
- _AI-generated [HTML meta tags](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta)_: We should have specific tags to describe this type of content. Today we have the [robots meta tags](https://moz.com/learn/seo/robots-meta-directives) that informs a crawler/bot if they should crawl/index that page. The same idea to inform a crawler about the type of content that‚Äôs included in that page. This will be useful for search engine crawlers. We might not want to train a future LLM on AI-generated text. This is not a [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago).  

And there you go... that's a lot of text in a blog post. I really enjoyed the creative and research process I've been through to be able to express myself better here. No LLM was used to write a sentence or paragraph here :-)
